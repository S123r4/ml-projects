# ML-project
smart language filter for hate speech and offensive language using ML.

In todayâ€™s digital world, people often express their opinions online, but sometimes this leads
to the spread of hateful or offensive messages. This project aims to create a tool that can
automatically check written messages and identify whether they contain hate speech, are
simply offensive, or are normal and harmless. The goal is to help online platforms, schools,
and communities keep their spaces respectful and safe for everyone.
The system works by learning from thousands of real-life examples of online comments. It
studies patterns in how people write when being respectful versus when they use harmful or
aggressive language. Once trained, the tool can quickly scan new messages and give a result
within seconds.
